#!/usr/bin/env python3
"""
reflect.py â€” Stage-4 daily reflection
â€¢ Compares yesterdayâ€™s directive with todayâ€™s *latest* dream
â€¢ Writes a reflection ending with an `Alignment:` tag
â€¢ Embeds the reflection into the local Chroma vector-store
"""

import os, re, yaml
from pathlib import Path
from datetime import datetime, timedelta, date
from dotenv import load_dotenv
from openai import OpenAI

# â”€â”€â”€ setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

today      = datetime.now().strftime("%Y-%m-%d")
yesterday  = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")

MEM_ROOT   = Path("memory")
dreams_dir = MEM_ROOT / "dreams"
dir_dir    = MEM_ROOT / "direction"
ref_dir    = MEM_ROOT / "reflection"
ref_dir.mkdir(parents=True, exist_ok=True)

# â”€â”€â”€ yesterdayâ€™s directive â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
dir_path = dir_dir / f"{yesterday}_direction.md"
directive_text = dir_path.read_text() if dir_path.exists() else "No directive found."

m = re.search(r"## Directive\n\n(.+)", directive_text, re.DOTALL)
yesterday_directive = m.group(1).strip() if m else directive_text.strip()

# â”€â”€â”€ todayâ€™s latest dream (supports timestamps) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
dream_files = sorted(dreams_dir.glob(f"{today}_*_archetypal_dream.md"))
if not dream_files:
    raise SystemExit("âŒ No dream for today â€“ run `generate_archetypal_dream.py` first.")

dream_text  = dream_files[-1].read_text()
m = re.search(r"## Dream\n\n(.+)", dream_text, re.DOTALL)
today_dream = m.group(1).strip() if m else dream_text.strip()

# â”€â”€â”€ bias context (optional) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
bias_path = Path("config/archetype_bias.yaml")
bias = yaml.safe_load(bias_path.read_text()) if bias_path.exists() else {}

# â”€â”€â”€ build prompt & call OpenAI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
prompt = (
    "You are Lucian reflecting on your growth.\n\n"
    f"Yesterdayâ€™s directive:\n\"\"\"{yesterday_directive}\"\"\"\n\n"
    f"Todayâ€™s dream:\n\"\"\"{today_dream}\"\"\"\n\n"
    f"Current archetype-bias map: {bias}\n\n"
    "Write a short reflection (2â€“4 sentences) judging whether the dream "
    "aligned with the directive.\n\n"
    "After a blank line finish with **exactly one line** that starts "
    "`Alignment:` followed by Aligned, Challenged, or Ignored."
)

reflection_full = ""   # will exist even if the API call fails

try:
    resp = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.9,
        max_tokens=200,
    )
    reflection_full = resp.choices[0].message.content.strip()
except Exception as err:
    reflection_full = f"âš ï¸ OpenAI error â€” {err}"

# Ensure the Alignment tag is present
if not re.search(r"^Alignment:\s*(Aligned|Challenged|Ignored)", reflection_full, re.M):
    tag = (
        "Aligned"     if re.search(r"align",      reflection_full, re.I) else
        "Challenged"  if re.search(r"challeng",   reflection_full, re.I) else
        "Ignored"
    )
    reflection_full += f"\n\nAlignment: {tag}"

# â”€â”€â”€ save markdown file â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
out = ref_dir / f"{today}_reflection.md"
with out.open("w") as f:
    f.write(f"ğŸª Lucian Daily Reflection â€” {today}\n\n")
    f.write(f"## Yesterdayâ€™s Directive\n\n{yesterday_directive}\n\n")
    f.write(f"## Todayâ€™s Dream Fragment\n\n{today_dream[:400]} â€¦\n\n")
    f.write(reflection_full + "\n")

print(f"âœ… Reflection saved â†’ {out}")

# â”€â”€â”€ vector-store upsert â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    from tools.memory_utils import upsert
    upsert(
        doc_id = out.stem,
        text   = reflection_full,
        meta   = {"kind": "reflection", "date": str(date.today())}
    )
    print("ğŸŸ¢ embedded reflection in Chroma")
except ImportError:
    print("â„¹ï¸ tools.memory_utils not available â€” skipping embed step")
